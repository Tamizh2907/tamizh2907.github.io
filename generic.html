<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Thamizhiniyan Pugazhenthi's Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a class="logo">Portfolio</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">About Me</a></li>
							<li class="active"><a href="generic.html">Projects</a></li>
						</ul>	
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/thamizhiniyan-pugazhenthi-92924a102/" class="icon brands fa-linkedin"><span class="label">linkedin</span></a></li>
							<li><a href="https://github.com/Tamizh2907/" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
					
						<!-- Featured Post -->
							<article class="post featured">
								<header class="major">
									<h2 style="font-size:40px;"><a>Data Analysis Projects</a></h2>
								</header>
							</article>
						<!-- Posts -->
							<section class="posts">
								<article>
									<header>
										<h2>Exploratory data analysis on the dataset of cyber security course from FutureLearn - a digital education platform</h2>
									</header>
									<p>
										In FutureLearn MOOC data set, there are different sets of data files from seven different runs of cyber security course on different time frames from FutureLearn website. Each set contains enrollments, questionresponse, step activity, team members, video stats, weekly sentiment survey, leaving survey and archetypes.  Different analyses have been drawn regarding similarities, differences, positives, negatives, and the improvements they can make along with the recommendations we can tell the FutureLearn team to enhance the user experience.<br />
										Languages and Tools - R, tidyverse, ggplot2
									</p>
									<ul class="actions special">
										<li><a href="https://github.com/Tamizh2907/LearningAnalytics" class="button">View Project</a></li>
									</ul>
								</article>
								<article>
									<header>
										<h2>Exploratory data analysis on the dataset of Facebook's Altoona data center</h2>
									</header>
									<p>
										The network traffic observed in the Altoona Facebook datacenter is the subject of this project. There are three clusters in the data center i.e., Cluster A is for Database, Cluster B is for Web servers and Cluster C is for Hadoop servers. Since we are working only with Cluster A and Cluster C, both of them have same set of columns. Each has 273 bz2 files in compressed format. Upon decompressing, each file is of tsv type with columns - timestamp, packet length, anonymized source IP, anonymized destination IP, anonymized source L4 Port, anonymized destination L4 Port, IP protocol, anonymized source hostprefix, anonymized destination hostprefix, anonymized source Rack, anonymized destination Rack, anonymized source Pod, anonymized destination Pod, intercluster, interdatacenter. All the data fields are anonymized for confidentiality. We analysed the dataset with respect to each of the above columns to identify the characteristics of the dataset.<br />
										Languages and Tools - R, tidyverse, ggplot2, ggnetwork
									</p>
									<ul class="actions special">
										<li><a href="https://github.com/Tamizh2907/FacebookAnalytics" class="button">View Project</a></li>
									</ul>
								</article>
								<article>
									<header>
										<h2>Big Data Analytics with PySpark</h2>
									</header>
									<p>
										Working with New York city taxi dataset with five dataset sizes - 'S', 'M', 'L', 'XL' and 'XXL' and two formats - parquet and delta. </br>
										Inputs - 
														  NYC Taxi Trips dataset - list of recorded taxi trips, each with several characteristics, namely: distance, number of passengers, origin zone, destination zone and trip cost (total amount charged to customer).</br>
														  NYC Zones dataset - list of zones wherein trips can originate/terminate.
													  <br />
										Tasks -
										Data Cleaning
										Add new columns
										Zone summarisation and ranking
										Record the total and task-specific execution times for each dataset size and format
										
										Languages and Tools - PySpark, pandas
									</p>
									<ul class="actions special">
										<li><a href="https://github.com/Tamizh2907/BigDataAnalyticsProject" class="button">View Project</a></li>
									</ul>
								</article>
							</section>
							<!-- Featured Post -->
								<article class="post featured">
									<header class="major">
										<h2 style="font-size:40px;"><a>Machine Learning Projects</a></h2>
									</header>
								</article>
							<!-- Posts -->
								<section class="posts">
									<article>
										<header>
											<h2>State Farm Distracted Driver Detection</h2>
										</header>
										<p>
											The goal of this project is to detect distracted driver images of the set of input images with the help of machine learning. The original question was originally adapted from one of the kaggle prediction competitions - https://www.kaggle.com/c/state-farm-distracted-driver-detection. The process started with the data pre-processing method which includes the preparation of images with the necessary folder structure according to the libraries I am going to use. The project was planned with with k-fold cross validation. With sklearn and stratified kfold, the CNN model used eleven splits since the number of classes is ten, but the process could not cross one iteration since I used three layers with 1024, 512 and output layer is 10 for 10 different classes. Since it cannot afford the (73728*1024) trainable parameters after one iteration due to OOM (Out of memory) error, I was forced to change my code to normal training-validation with one iteration. After 100 epochs, 97% training accuracy was achieved and more than 96% validation accuracy with the training loss is less than 0.1 and validation loss is 0.144. <br />
											Languages and Tools - Python, kaggle, Tensorflow 2.8.0, CNN, pandas, matplotlib.
										</p>
										<ul class="actions special">
											<li><a href="https://github.com/Tamizh2907/MachineLearningDriverdistraction" class="button">View Project</a></li>
										</ul>
									</article>
									<article>
										<header>
											<h2>CycleGAN</h2>
										</header>
										<p>
											Used an existing model â€“ CycleGAN to implement the unpaired image to image translation between human faces and cats/dogs.<br />
											Languages and Tools - Python, Tensorflow 2.8.0, GAN, Colab, Reinforcement learning.
										</p>
										<ul class="actions special">
											<li><a href="https://github.com/Tamizh2907/DeepLearningProject/blob/main/cyclegan.ipynb" class="button">View Project</a></li>
										</ul>
									</article>
									<article>
										<header>
											<h2>Birds classification</h2>
										</header>
										<p>
											Utilised VGG16 pre-trained weights from ImageNet, classified birds of over 250 classes and constructed the code with TensorFlow and Keras. The execution time was shortened by using prefetch for parallel processing. Data augmentation was used to avoid overfitting. Increased accuracy by over 96% with good precision and recall score.<br />
											Languages and Tools - Python, Tensorflow 2.8.0, CNN, Anaconda, Reinforcement learning, pandas, NumPy, scikit-learn.
										</p>
										<ul class="actions special">
											<li><a href="https://github.com/Tamizh2907/DeepLearningProject/blob/main/Birdsclassification.ipynb" class="button">View Project</a></li>
										</ul>
									</article>
									<article>
										<header>
											<h2>Language model - Next word prediction</h2>
										</header>
										<p>
											Built model with the embedding layer, LSTM layer and dense layer with the softmax activation function. Achieved up to 91% accuracy with the model which can improve further with more epochs. Tokenizer was used to improve word mapping.<br />
											Languages and Tools - Python, Keras, Tensorflow 2.8.0, LSTM, Tokenizer, Anaconda.
										</p>
										<ul class="actions special">
											<li><a href="https://github.com/Tamizh2907/DeepLearningProject/blob/main/textgenerationnlp.ipynb" class="button">View Project</a></li>
										</ul>
									</article>
								</section>
						
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
